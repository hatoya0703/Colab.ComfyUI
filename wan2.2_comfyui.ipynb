{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Wan2.2 Video Generation on Google Colab\n\nWan2.2ã‚’Google Colabã§å‹•ã‹ã™ãŸã‚ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n\n## ç‰¹å¾´\n- **Google Driveã«ãƒ¢ãƒ‡ãƒ«ä¿å­˜** - æ¯å›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸è¦\n- **è¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ** - ç”¨é€”ã«å¿œã˜ã¦é¸æŠå¯èƒ½\n- **GGUFé‡å­åŒ–å¯¾å¿œ** - T4ã§ã‚‚14Bãƒ¢ãƒ‡ãƒ«å‹•ä½œå¯èƒ½\n- **ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ¼ãƒ‰å¯¾å¿œ** - WanVideoWrapper, GGUF, VideoHelperSuite\n\n## å¯¾å¿œãƒ¢ãƒ‡ãƒ«\n\n### Diffusion Modelsï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼å‹ï¼‰\n| ãƒ¢ãƒ‡ãƒ« | ã‚µã‚¤ã‚º | VRAMç›®å®‰ | ç”¨é€” |\n|--------|--------|----------|------|\n| I2V-14B-fp16 | 28.6GB | 24GB+ | é«˜å“è³ªI2V |\n| I2V-14B-fp8 | 14.3GB | ~16GB | ä¸­VRAM I2V |\n| I2V-14B-GGUF-Q4 | ~8GB | ~12GB | T4å¯¾å¿œI2V |\n| T2V-14B-fp16 | 28.6GB | 24GB+ | é«˜å“è³ªT2V |\n| T2V-14B-fp8 | 14.3GB | ~16GB | ä¸­VRAM T2V |\n| TI2V-5B | ~10GB | ~8GB | è»½é‡ç‰ˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆ+ç”»åƒï¼‰ |\n| Animate-14B-GGUF-Q4 | ~8GB | ~12GB | ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ |\n\n### High Noise vs Low Noise\n- **High Noise**: å¤§ããªå‹•ããƒ»å¤‰åŒ–ã‚’ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰\n- **Low Noise**: å…¥åŠ›ã«ã‚ˆã‚Šå¿ å®Ÿã€å¤‰åŒ–æ§ãˆã‚\n\n## ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼\n| ãƒ•ã‚¡ã‚¤ãƒ« | ç”¨é€” | å¿…è¦ãƒ¢ãƒ‡ãƒ« |\n|----------|------|------------|\n| t2v-14b.json | ãƒ†ã‚­ã‚¹ãƒˆâ†’å‹•ç”» | T2V-14B + TextEncoder + VAE |\n| i2v-14b.json | ç”»åƒâ†’å‹•ç”» | I2V-14B + TextEncoder + VAE + CLIP Vision |\n| low-vram-ti2v.json | T4å¯¾å¿œTI2V | TI2V-5B + LoRA + TextEncoder + VAE |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. GPUç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "!nvidia-smi\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"VRAM: {gpu_memory:.1f} GB\")\n",
    "    if gpu_memory >= 40:\n",
    "        print(\"æ¨å¥¨: fp16ãƒ¢ãƒ‡ãƒ« (I2V-14B, T2V-14B)\")\n",
    "    elif gpu_memory >= 20:\n",
    "        print(\"æ¨å¥¨: fp16ã¾ãŸã¯GGUF-Q8\")\n",
    "    else:\n",
    "        print(\"æ¨å¥¨: GGUF-Q4é‡å­åŒ–ãƒ¢ãƒ‡ãƒ« or TI2V-5B\")\n",
    "else:\n",
    "    print(\"GPU not available!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Google Driveãƒã‚¦ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\nimport os\n\ndrive.mount('/content/drive')\n\n# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\nDRIVE_MODEL_DIR = \"/content/drive/MyDrive/ComfyUI_Wan22\"\n\n# ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆä½œæˆ\nfolders = [\n    f\"{DRIVE_MODEL_DIR}/diffusion_models\",\n    f\"{DRIVE_MODEL_DIR}/text_encoders\",\n    f\"{DRIVE_MODEL_DIR}/vae\",\n    f\"{DRIVE_MODEL_DIR}/clip_vision\",\n    f\"{DRIVE_MODEL_DIR}/loras\",\n    f\"{DRIVE_MODEL_DIR}/workflows\",\n    f\"{DRIVE_MODEL_DIR}/outputs\"\n]\nfor folder in folders:\n    os.makedirs(folder, exist_ok=True)\n\nprint(f\"ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ: {DRIVE_MODEL_DIR}\")\n\n# GitHubã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\nGITHUB_RAW = \"https://raw.githubusercontent.com/hatoya0703/Colab.Wan/main/workflows\"\nworkflows = [\n    \"t2v-14b.json\",\n    \"i2v-14b.json\",\n    \"low-vram-ti2v.json\"\n]\nprint(\"\\nãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’GitHubã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:\")\nfor wf in workflows:\n    dest = f\"{DRIVE_MODEL_DIR}/workflows/{wf}\"\n    if not os.path.exists(dest):\n        !wget -q -O \"{dest}\" \"{GITHUB_RAW}/{wf}\"\n        print(f\"  DL: {wf}\")\n    else:\n        print(f\"  æ—¢å­˜: {wf}\")\n\nprint(\"\\næ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«:\")\n!ls -la \"{DRIVE_MODEL_DIR}/diffusion_models/\" 2>/dev/null || echo \"(ãªã—)\"\n!ls -la \"{DRIVE_MODEL_DIR}/text_encoders/\" 2>/dev/null || echo \"(ãªã—)\"\nprint(\"\\næ—¢å­˜ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:\")\n!ls -la \"{DRIVE_MODEL_DIR}/workflows/\" 2>/dev/null || echo \"(ãªã—)\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title è¨­å®šãƒ‘ãƒãƒ« { display-mode: \"form\" }\n\n#@markdown ### Low-VRAM TI2Vï¼ˆT4å¯¾å¿œï¼‰\nDL_LOW_VRAM_TI2V = False #@param {type:\"boolean\"}\n\n#@markdown ### Diffusionãƒ¢ãƒ‡ãƒ«ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰\nDL_I2V_14B_FP16 = False #@param {type:\"boolean\"}\nDL_I2V_14B_FP8 = False #@param {type:\"boolean\"}\nDL_I2V_14B_GGUF_Q4 = True #@param {type:\"boolean\"}\nDL_ANIMATE_14B_GGUF_Q4 = False #@param {type:\"boolean\"}\nDL_TI2V_5B = False #@param {type:\"boolean\"}\nDL_T2V_14B_FP16 = False #@param {type:\"boolean\"}\nDL_T2V_14B_FP8 = False #@param {type:\"boolean\"}\n\n#@markdown ### å…±é€šãƒ¢ãƒ‡ãƒ«ï¼ˆDiffusion Modelsç”¨ï¼‰\nDL_TEXT_ENCODER = True #@param {type:\"boolean\"}\nDL_VAE = True #@param {type:\"boolean\"}\nDL_CLIP_VISION = True #@param {type:\"boolean\"}\nDL_LORA_ANIMATE = False #@param {type:\"boolean\"}\n\n# é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º\nprint(\"=== ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ ===\")\nselected = []\nif DL_LOW_VRAM_TI2V: selected.append(\"Low-VRAM TI2V (5B + LoRA)\")\nif DL_I2V_14B_FP16: selected.append(\"I2V-14B-fp16 (High+Low Noise)\")\nif DL_I2V_14B_FP8: selected.append(\"I2V-14B-fp8 (High Noise)\")\nif DL_I2V_14B_GGUF_Q4: selected.append(\"I2V-14B-GGUF-Q4\")\nif DL_ANIMATE_14B_GGUF_Q4: selected.append(\"Animate-14B-GGUF-Q4\")\nif DL_TI2V_5B: selected.append(\"TI2V-5B\")\nif DL_T2V_14B_FP16: selected.append(\"T2V-14B-fp16 (High+Low Noise)\")\nif DL_T2V_14B_FP8: selected.append(\"T2V-14B-fp8 (High Noise)\")\nif DL_TEXT_ENCODER: selected.append(\"Text Encoder (umt5-xxl-fp8)\")\nif DL_VAE: selected.append(\"VAE\")\nif DL_CLIP_VISION: selected.append(\"CLIP Vision\")\nif DL_LORA_ANIMATE: selected.append(\"LoRA (WanAnimate relight)\")\n\nfor s in selected:\n    print(f\"  - {s}\")\nif not selected:\n    print(\"  (ãªã— - æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨)\")\n\n# Low-VRAM TI2Vä½¿ç”¨æ™‚ã®æ³¨æ„\nif DL_LOW_VRAM_TI2V:\n    print(\"\\nğŸ’¡ Low-VRAM TI2Vé¸æŠæ™‚:\")\n    print(\"  â†’ T4 GPUå¯¾å¿œï¼ˆ~12GB VRAMï¼‰\")\n    print(\"  â†’ TI2V-5Bãƒ¢ãƒ‡ãƒ« + PusaV1 LoRAä½¿ç”¨\")\n    print(\"  â†’ SageAttentionæœ‰åŠ¹åŒ–æ¨å¥¨\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå› or è¿½åŠ æ™‚ã®ã¿å®Ÿè¡Œï¼‰\n",
    "\n",
    "æ—¢ã«Google Driveã«ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—å¯èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\nfrom huggingface_hub import hf_hub_download\nimport os\nimport shutil\n\ndef download_model(repo_id, filename, dest_folder, dest_filename=None):\n    \"\"\"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Google Driveã«ä¿å­˜\"\"\"\n    dest_path = f\"{DRIVE_MODEL_DIR}/{dest_folder}/{dest_filename or os.path.basename(filename)}\"\n    if os.path.exists(dest_path):\n        print(f\"  æ—¢å­˜: {os.path.basename(dest_path)}\")\n        return\n    print(f\"  DLä¸­: {filename}\")\n    downloaded = hf_hub_download(repo_id=repo_id, filename=filename)\n    shutil.copy(downloaded, dest_path)\n    print(f\"  ä¿å­˜: {dest_path}\")\n\n# === Low-VRAM TI2V ===\nif DL_LOW_VRAM_TI2V:\n    print(\"\\n=== Low-VRAM TI2V ===\")\n    print(\"\\n[TI2V-5B Diffusion Model]\")\n    download_model(\n        \"Comfy-Org/Wan_2.2_ComfyUI_repackaged\",\n        \"split_files/diffusion_models/wan2.2_ti2v_5B_fp16.safetensors\",\n        \"diffusion_models\"\n    )\n    print(\"\\n[Text Encoder (scaled)]\")\n    download_model(\n        \"Comfy-Org/Wan_2.1_ComfyUI_repackaged\",\n        \"split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors\",\n        \"text_encoders\"\n    )\n    print(\"\\n[VAE (wan2.2)]\")\n    download_model(\n        \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n        \"split_files/vae/wan2.2_vae.safetensors\",\n        \"vae\"\n    )\n    print(\"\\n[PusaV1 LoRA]\")\n    download_model(\n        \"Kijai/WanVideo_comfy\",\n        \"Pusa/Wan21_PusaV1_LoRA_14B_rank512_bf16.safetensors\",\n        \"loras\",\n        \"Wan21_PusaV1_LoRA_14B_rank512_bf16.safetensors\"\n    )\n    print(\"\\n[CLIP Vision]\")\n    download_model(\n        \"Comfy-Org/Wan_2.1_ComfyUI_repackaged\",\n        \"split_files/clip_vision/clip_vision_h.safetensors\",\n        \"clip_vision\"\n    )\n\n# === Diffusion Models ===\nprint(\"\\n=== Diffusion Models ===\")\n\nif DL_I2V_14B_FP16:\n    print(\"\\n[I2V-14B-fp16 High Noise]\")\n    download_model(\n        \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n        \"split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp16.safetensors\",\n        \"diffusion_models\"\n    )\n    print(\"\\n[I2V-14B-fp16 Low Noise]\")\n    download_model(\n        \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n        \"split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp16.safetensors\",\n        \"diffusion_models\"\n    )\n\nif DL_I2V_14B_FP8:\n    print(\"\\n[I2V-14B-fp8 High Noise]\")\n    download_model(\n        \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n        \"split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors\",\n        \"diffusion_models\"\n    )\n\nif DL_I2V_14B_GGUF_Q4:\n    print(\"\\n[I2V-14B-GGUF-Q4]\")\n    download_model(\n        \"city96/Wan2.1-I2V-14B-480P-GGUF\",\n        \"wan2.1-i2v-14b-480p-Q4_K_S.gguf\",\n        \"diffusion_models\"\n    )\n\nif DL_ANIMATE_14B_GGUF_Q4:\n    print(\"\\n[Animate-14B-GGUF-Q4]\")\n    download_model(\n        \"Kijai/WanVideo_comfy_GGUF\",\n        \"Wan2_2_Animate_14B_Q4_K_M.gguf\",\n        \"diffusion_models\"\n    )\n\nif DL_TI2V_5B:\n    print(\"\\n[TI2V-5B]\")\n    download_model(\n        \"Comfy-Org/Wan_2.2_ComfyUI_repackaged\",\n        \"split_files/diffusion_models/wan2.2_ti2v_5B_fp16.safetensors\",\n        \"diffusion_models\"\n    )\n\nif DL_T2V_14B_FP16:\n    print(\"\\n[T2V-14B-fp16 High Noise]\")\n    download_model(\n        \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n        \"split_files/diffusion_models/wan2.2_t2v_high_noise_14B_fp16.safetensors\",\n        \"diffusion_models\"\n    )\n    print(\"\\n[T2V-14B-fp16 Low Noise]\")\n    download_model(\n        \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n        \"split_files/diffusion_models/wan2.2_t2v_low_noise_14B_fp16.safetensors\",\n        \"diffusion_models\"\n    )\n\nif DL_T2V_14B_FP8:\n    print(\"\\n[T2V-14B-fp8 High Noise]\")\n    download_model(\n        \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n        \"split_files/diffusion_models/wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors\",\n        \"diffusion_models\"\n    )\n\n# === Text Encoder ===\nif DL_TEXT_ENCODER:\n    print(\"\\n=== Text Encoder ===\")\n    download_model(\n        \"Kijai/WanVideo_comfy\",\n        \"umt5-xxl-enc-fp8_e4m3fn.safetensors\",\n        \"text_encoders\"\n    )\n\n# === VAE ===\nif DL_VAE:\n    print(\"\\n=== VAE ===\")\n    download_model(\n        \"Kijai/WanVideo_comfy\",\n        \"Wan2_1_VAE_bf16.safetensors\",\n        \"vae\"\n    )\n\n# === CLIP Vision ===\nif DL_CLIP_VISION:\n    print(\"\\n=== CLIP Vision ===\")\n    download_model(\n        \"Comfy-Org/Wan_2.1_ComfyUI_repackaged\",\n        \"split_files/clip_vision/clip_vision_h.safetensors\",\n        \"clip_vision\"\n    )\n\n# === LoRA ===\nif DL_LORA_ANIMATE:\n    print(\"\\n=== LoRA ===\")\n    download_model(\n        \"Kijai/WanVideo_comfy\",\n        \"Wan22_relight/WanAnimate_relight_lora_fp16.safetensors\",\n        \"loras\",\n        \"WanAnimate_relight_lora_fp16.safetensors\"\n    )\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†!\")\nprint(\"=\"*50)\nprint(\"\\nä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«:\")\n!ls -lh \"{DRIVE_MODEL_DIR}/diffusion_models/\"\n!ls -lh \"{DRIVE_MODEL_DIR}/text_encoders/\"\n!ls -lh \"{DRIVE_MODEL_DIR}/vae/\"\n!ls -lh \"{DRIVE_MODEL_DIR}/loras/\" 2>/dev/null || echo \"(ãªã—)\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. ComfyUI + ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ¼ãƒ‰ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\nimport os\n\n# ComfyUI\nif not os.path.exists(\"/content/ComfyUI\"):\n    !git clone https://github.com/comfyanonymous/ComfyUI.git /content/ComfyUI\n%cd /content/ComfyUI\n!pip install -q -r requirements.txt\n!pip install -q huggingface_hub\nprint(\"ComfyUI installed.\")\n\n# Kijai WanVideoWrapper\nif not os.path.exists(\"custom_nodes/ComfyUI-WanVideoWrapper\"):\n    !git clone https://github.com/kijai/ComfyUI-WanVideoWrapper.git custom_nodes/ComfyUI-WanVideoWrapper\n    !pip install -q -r custom_nodes/ComfyUI-WanVideoWrapper/requirements.txt\nprint(\"WanVideoWrapper installed.\")\n\n# GGUF support\nif not os.path.exists(\"custom_nodes/ComfyUI-GGUF\"):\n    !git clone https://github.com/city96/ComfyUI-GGUF.git custom_nodes/ComfyUI-GGUF\n    !pip install -q gguf\nprint(\"GGUF support installed.\")\n\n# VideoHelperSuite\nif not os.path.exists(\"custom_nodes/ComfyUI-VideoHelperSuite\"):\n    !git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git custom_nodes/ComfyUI-VideoHelperSuite\n    !pip install -q -r custom_nodes/ComfyUI-VideoHelperSuite/requirements.txt 2>/dev/null || true\nprint(\"VideoHelperSuite installed.\")\n\n# KJNodes (for Low-VRAM TI2V workflow)\nif not os.path.exists(\"custom_nodes/ComfyUI-KJNodes\"):\n    !git clone https://github.com/kijai/ComfyUI-KJNodes.git custom_nodes/ComfyUI-KJNodes\n    !pip install -q -r custom_nodes/ComfyUI-KJNodes/requirements.txt 2>/dev/null || true\nprint(\"KJNodes installed.\")\n\n# rgthree-comfy (for Low-VRAM TI2V workflow)\nif not os.path.exists(\"custom_nodes/rgthree-comfy\"):\n    !git clone https://github.com/rgthree/rgthree-comfy.git custom_nodes/rgthree-comfy\nprint(\"rgthree-comfy installed.\")\n\n# SageAttention (for Low-VRAM optimization)\n!pip install -q sageattention\nprint(\"SageAttention installed.\")\n\nprint(\"\\nAll custom nodes installed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. ãƒ¢ãƒ‡ãƒ«ã‚’ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã§æ¥ç¶š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\nos.chdir(\"/content/ComfyUI\")\n\n# æ—¢å­˜ã®modelsãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤\n!rm -rf models/diffusion_models models/text_encoders models/vae models/clip_vision models/loras 2>/dev/null\n\n# ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆï¼ˆãƒ¢ãƒ‡ãƒ«ï¼‰\nlinks = [\n    (f\"{DRIVE_MODEL_DIR}/diffusion_models\", \"models/diffusion_models\"),\n    (f\"{DRIVE_MODEL_DIR}/text_encoders\", \"models/text_encoders\"),\n    (f\"{DRIVE_MODEL_DIR}/vae\", \"models/vae\"),\n    (f\"{DRIVE_MODEL_DIR}/clip_vision\", \"models/clip_vision\"),\n    (f\"{DRIVE_MODEL_DIR}/loras\", \"models/loras\"),\n]\n\nfor src, dst in links:\n    if os.path.exists(src):\n        !ln -sf \"{src}\" \"{dst}\"\n        print(f\"ãƒªãƒ³ã‚¯: {dst} -> {src}\")\n\n# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯\nos.makedirs(\"user/default\", exist_ok=True)\n!rm -rf user/default/workflows 2>/dev/null\nif os.path.exists(f\"{DRIVE_MODEL_DIR}/workflows\"):\n    !ln -sf \"{DRIVE_MODEL_DIR}/workflows\" \"user/default/workflows\"\n    print(f\"ãƒªãƒ³ã‚¯: user/default/workflows -> {DRIVE_MODEL_DIR}/workflows\")\n\nprint(\"\\n=== ãƒ¢ãƒ‡ãƒ«ç¢ºèª ===\")\n!ls -la models/diffusion_models/\n!ls -la models/text_encoders/\n!ls -la models/vae/\n!ls -la models/clip_vision/\nprint(\"\\n=== ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç¢ºèª ===\")\n!ls -la user/default/workflows/ 2>/dev/null || echo \"workflows: (ãªã—)\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. ComfyUIèµ·å‹•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nos.chdir(\"/content/ComfyUI\")\n\n# Colab Secretsã‹ã‚‰NGROKãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—\nfrom google.colab import userdata\ntry:\n    NGROK_TOKEN = userdata.get('NGROK_TOKEN')\nexcept userdata.SecretNotFoundError:\n    NGROK_TOKEN = None\n    print(\"âš ï¸ NGROK_TOKEN ãŒ Colab Secrets ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n    print(\"  å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ ğŸ”‘ â†’ æ–°ã—ã„ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’è¿½åŠ  â†’ NGROK_TOKEN\")\n\n# ngrokãƒˆãƒ³ãƒãƒ«\nif NGROK_TOKEN:\n    !pip install -q pyngrok\n    from pyngrok import ngrok\n    ngrok.kill()  # æ—¢å­˜ã®ãƒˆãƒ³ãƒãƒ«ã‚’åœæ­¢\n    ngrok.set_auth_token(NGROK_TOKEN)\n    public_url = ngrok.connect(8188)\n    print(f\"\\n{'='*50}\")\n    print(f\"ComfyUI URL: {public_url}\")\n    print(f\"{'='*50}\\n\")\nelse:\n    print(\"=\"*50)\n    print(\"ngrokæœªè¨­å®š\")\n    print(\"Colabã®å‡ºåŠ›ãƒãƒ¼ãƒˆã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ãã ã•ã„\")\n    print(\"=\"*50)\n\n# ComfyUIèµ·å‹•\n!python main.py --listen 0.0.0.0 --port 8188"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Tips\n\n### 2å›ç›®ä»¥é™ã®èµ·å‹•\n1. ã‚»ãƒ«1 (GPUç¢ºèª)\n2. ã‚»ãƒ«2 (Google Driveãƒã‚¦ãƒ³ãƒˆ)\n3. ã‚»ãƒ«5 (ComfyUIã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«)\n4. ã‚»ãƒ«6 (ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯)\n5. ã‚»ãƒ«7 (ComfyUIèµ·å‹•)\n\nâ†’ ã‚»ãƒ«3,4ã¯ã‚¹ã‚­ãƒƒãƒ—å¯èƒ½\n\n### GPUåˆ¥æ¨å¥¨ãƒ¢ãƒ‡ãƒ«\n| GPU | VRAM | æ¨å¥¨ãƒ¢ãƒ‡ãƒ« |\n|-----|------|------------|\n| T4 | 15GB | GGUF-Q4, TI2V-5B, fp8 |\n| L4 | 24GB | fp16, fp8 |\n| A100 | 40GB | fp16 |\n\n### ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆ\n```\nGoogle Drive/MyDrive/ComfyUI_Wan22/\nâ”œâ”€â”€ diffusion_models/  # ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«\nâ”œâ”€â”€ text_encoders/     # ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼\nâ”œâ”€â”€ vae/               # VAE\nâ”œâ”€â”€ clip_vision/       # CLIP Vision\nâ”œâ”€â”€ loras/             # LoRA\nâ”œâ”€â”€ workflows/         # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆè‡ªå‹•èª­ã¿è¾¼ã¿ï¼‰\nâ””â”€â”€ outputs/           # å‡ºåŠ›å‹•ç”»\n```\n\n### 14Bæ¨å¥¨è¨­å®š\n- Sampler: `uni_pc`\n- Scheduler: `simple`\n- CFG: `5`\n- Steps: `30`\n- ModelSamplingSD3 shift: `3.0`"
  }
 ]
}